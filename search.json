[{"path":[]},{"path":"/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement codeofconduct@rstudio.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2019 Julia Silge Tyler Schnoebelen Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/tidylo.html","id":"a-motivating-example-what-words-are-important-to-a-text","dir":"Articles","previous_headings":"","what":"A motivating example: what words are important to a text?","title":"Tidy Log Odds","text":"multiple ways measure words (bigrams, units text) important text. can count words, measure tf-idf. package implements different approach measuring words important text, weighted log odds. log odds ratio way expressing probabilities, can weight log odds ratio implementation better job dealing different combinations words documents different counts. particular, use method outlined Monroe, Colaresi, Quinn (2008) posterior log odds ratios, assuming multinomial model Dirichlet prior. default prior estimated data , empirical Bayesian approach, uninformative prior also available. mean? means weighting using empirical Bayes estimation, take account sampling error measurements acknowledge certain ’ve counted something lot times less certain ’ve counted something times. weighting prior way, focus differences likely real, given evidence . Let’s look just example.","code":""},{"path":"/articles/tidylo.html","id":"jane-austen-and-bigrams","dir":"Articles","previous_headings":"","what":"Jane Austen and bigrams","title":"Tidy Log Odds","text":"Let’s explore six published, completed novels Jane Austen use tidytext package count bigrams (sequences two adjacent words) novel, focusing bigrams include upper case letters. (can look differences involving proper nouns way.) weighted log odds approach work equally well single words, kinds n-grams. Notice haven’t removed stop words, filtered rarely used words. done little pre-processing text data. Now let’s use bind_log_odds() function tidylo package find weighted log odds bigram. weighted log odds computed function also z-scores log odds; quantity useful comparing frequencies across categories sets relationship odds ratio straightforward weighting. bigrams highest weighted log odds books? highest log odds bigrams (bigrams likely come book, compared others) involve concepts specific novel, pump room Northanger Abbey sister/mother figures Sense & Sensibility. can make visualization well.  bigrams highest weighted log odds book. proper names characters tend unique book book unless ’re looking series like Harry Potter. comes identifying words phrases unique text, measure like tf-idf good job. way tf-idf calculated, distinguish words used texts. example, phrase “” used 100 times six Austen novels. “idf” tf-idf stands “inverse document frequency”. word texts, tf-idf zero . weighted log odds, however, book different value; case weighted log odds ranges 5.42 Persuasion (high) -2.27 Sense & Sensibility (suggests something style content suppressing phrase).","code":"library(dplyr) library(janeaustenr) library(tidytext) library(stringr)  tidy_bigrams <- austen_books() %>%   unnest_tokens(bigram, text, token=\"ngrams\", n = 2, to_lower = FALSE) %>%   filter(!str_detect(bigram, \"[A-Z]\"))  bigram_counts <- tidy_bigrams %>%   count(book, bigram, sort = TRUE)  bigram_counts #> # A tibble: 256,348 × 3 #>    book                bigram     n #>    <fct>               <chr>  <int> #>  1 Mansfield Park      of the   708 #>  2 Mansfield Park      to be    582 #>  3 Emma                to be    574 #>  4 Emma                of the   524 #>  5 Mansfield Park      in the   520 #>  6 Pride & Prejudice   of the   437 #>  7 Pride & Prejudice   to be    416 #>  8 Sense & Sensibility to be    410 #>  9 Persuasion          of the   409 #> 10 Emma                in the   405 #> # … with 256,338 more rows library(tidylo)  bigram_log_odds <- bigram_counts %>%   bind_log_odds(book, bigram, n)   bigram_log_odds %>%   arrange(-log_odds_weighted) #> # A tibble: 256,348 × 4 #>    book                bigram            n log_odds_weighted #>    <fct>               <chr>         <int>             <dbl> #>  1 Emma                any thing       150             13.3  #>  2 Northanger Abbey    pump room        23              9.32 #>  3 Sense & Sensibility any thing        58              9.17 #>  4 Northanger Abbey    the pump         22              9.11 #>  5 Northanger Abbey    the abbey        20              8.69 #>  6 Northanger Abbey    the general's    15              7.53 #>  7 Persuasion          any thing         5              7.36 #>  8 Emma                any body         61              6.72 #>  9 Emma                every body       67              6.61 #> 10 Sense & Sensibility the cottage      26              6.28 #> # … with 256,338 more rows library(ggplot2)  bigram_log_odds %>%   group_by(book) %>%   slice_max(log_odds_weighted, n = 10) %>%   ungroup %>%   mutate(bigram = reorder(bigram, log_odds_weighted)) %>%   ggplot(aes(log_odds_weighted, bigram, fill = book)) +   geom_col(show.legend = FALSE) +   facet_wrap(vars(book), scales = \"free\") +   labs(y = NULL)"},{"path":"/articles/tidylo.html","id":"counting-things-other-than-words","dir":"Articles","previous_headings":"","what":"Counting things other than words","title":"Tidy Log Odds","text":"Text analysis main motivator implementation weighted log odds, general approach measuring much likely one feature (kind feature, just word bigram) associated another set group (kind set, just document book). demonstrate , let’s look everybody’s favorite data cars. know relationship number gears engine shape vs? Now can use bind_log_odds() find weighted log odds number gears engine shape. First, let’s use default empirical Bayes prior. regularizes values. engine shape vs = 0, three gears highest weighted log odds engine shape vs = 1, four gears highest weighted log odds. dataset small enough can look count data see working. Now, let’s use uninformative prior, compare unweighted log odds. log odds farther zero regularized estimates. importantly, can notice approach useful initial motivating example text data also generally whenever counts kind groups sets want find feature likely come group, compared groups.","code":"gear_counts <- mtcars %>%   count(vs, gear)  gear_counts #>   vs gear  n #> 1  0    3 12 #> 2  0    4  2 #> 3  0    5  4 #> 4  1    3  3 #> 5  1    4 10 #> 6  1    5  1 regularized <- gear_counts %>%   bind_log_odds(vs, gear, n)  regularized #>   vs gear  n log_odds_weighted #> 1  0    3 12         1.1728347 #> 2  0    4  2        -1.3767516 #> 3  0    5  4         0.4033125 #> 4  1    3  3        -1.1354777 #> 5  1    4 10         1.5661168 #> 6  1    5  1        -0.4362340 unregularized <- gear_counts %>%   bind_log_odds(vs, gear, n, uninformative = TRUE, unweighted = TRUE)  unregularized #>   vs gear  n   log_odds log_odds_weighted #> 1  0    3 12  0.6968169         1.8912729 #> 2  0    4  2 -1.2527630        -1.9691060 #> 3  0    5  4  0.3249262         0.5549172 #> 4  1    3  3 -0.9673459        -1.7407107 #> 5  1    4 10  1.1451323         2.8421436 #> 6  1    5  1 -0.5268260        -0.6570674"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tyler Schnoebelen. Author. Julia Silge. Author, maintainer, copyright holder. Alex Hayes. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Schnoebelen T, Silge J, Hayes (2022). tidylo: Weighted Tidy Log Odds Ratio. R package version 0.1.0.9000, http://github.com/juliasilge/tidylo.","code":"@Manual{,   title = {tidylo: Weighted Tidy Log Odds Ratio},   author = {Tyler Schnoebelen and Julia Silge and Alex Hayes},   year = {2022},   note = {R package version 0.1.0.9000},   url = {http://github.com/juliasilge/tidylo}, }"},{"path":"/index.html","id":"tidylo-weighted-tidy-log-odds-ratio-️","dir":"","previous_headings":"","what":"Weighted Tidy Log Odds Ratio","title":"Weighted Tidy Log Odds Ratio","text":"Authors: Julia Silge, Alex Hayes, Tyler SchnoebelenLicense: MIT can measure usage frequency feature, words, differs across group set, documents? One option use log odds ratio, log odds ratio alone account sampling variability; haven’t counted every feature number times know differences meaningful? Enter weighted log odds, tidylo provides implementation , using tidy data principles. particular, use method outlined Monroe, Colaresi, Quinn (2008) weight log odds ratio prior. default, prior estimated data , empirical Bayes approach, uninformative prior also available.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Weighted Tidy Log Odds Ratio","text":"can install released version tidylo CRAN : can install development version GitHub remotes:","code":"install.packages(\"tidylo\") # install.packages(\"devtools\") devtools::install_github(\"juliasilge/tidylo\")"},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Weighted Tidy Log Odds Ratio","text":"Using weighted log odds great approach text analysis want measure word usage differs across set documents. Let’s explore six published, completed novels Jane Austen use tidytext package count bigrams (sequences two adjacent words) novel. weighted log odds approach work equally well single words. Now let’s use bind_log_odds() function tidylo package find weighted log odds bigram. weighted log odds computed function also z-scores log odds; quantity useful comparing frequencies across categories sets relationship odds ratio straightforward weighting. bigrams highest weighted log odds books? bigrams likely come book, compared others, involve proper nouns. can make visualization well.","code":"library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(janeaustenr) library(tidytext)  tidy_bigrams <- austen_books() %>%     unnest_tokens(bigram, text, token = \"ngrams\", n = 2) %>%     filter(!is.na(bigram))  bigram_counts <- tidy_bigrams %>%     count(book, bigram, sort = TRUE)  bigram_counts #> # A tibble: 300,903 × 3 #>    book                bigram     n #>    <fct>               <chr>  <int> #>  1 Mansfield Park      of the   712 #>  2 Mansfield Park      to be    612 #>  3 Emma                to be    586 #>  4 Mansfield Park      in the   533 #>  5 Emma                of the   529 #>  6 Pride & Prejudice   of the   439 #>  7 Emma                it was   430 #>  8 Pride & Prejudice   to be    422 #>  9 Sense & Sensibility to be    418 #> 10 Emma                in the   416 #> # … with 300,893 more rows library(tidylo)  bigram_log_odds <- bigram_counts %>%     bind_log_odds(book, bigram, n)   bigram_log_odds %>%     arrange(-log_odds_weighted) #> # A tibble: 300,903 × 4 #>    book                bigram                n log_odds_weighted #>    <fct>               <chr>             <int>             <dbl> #>  1 Mansfield Park      sir thomas          266              27.2 #>  2 Pride & Prejudice   mr darcy            230              27.0 #>  3 Emma                mr knightley        239              25.9 #>  4 Sense & Sensibility mrs jennings        185              24.3 #>  5 Emma                mrs weston          208              24.2 #>  6 Mansfield Park      miss crawford       196              23.4 #>  7 Persuasion          captain wentworth   143              23.0 #>  8 Persuasion          mr elliot           133              22.2 #>  9 Emma                mr elton            174              22.1 #> 10 Mansfield Park      mrs norris          148              20.3 #> # … with 300,893 more rows library(ggplot2)  bigram_log_odds %>%     group_by(book) %>%     slice_max(log_odds_weighted, n = 10) %>%     ungroup() %>%     mutate(bigram = reorder(bigram, log_odds_weighted)) %>%     ggplot(aes(log_odds_weighted, bigram, fill = book)) +     geom_col(show.legend = FALSE) +     facet_wrap(vars(book), scales = \"free\") +     labs(y = NULL)"},{"path":"/index.html","id":"community-guidelines","dir":"","previous_headings":"Example","what":"Community Guidelines","title":"Weighted Tidy Log Odds Ratio","text":"project released Contributor Code Conduct. contributing project, agree abide terms. Feedback, bug reports (fixes!), feature requests welcome; file issues seek support .","code":""},{"path":"/reference/bind_log_odds.html","id":null,"dir":"Reference","previous_headings":"","what":"Bind the weighted log odds to a tidy dataset — bind_log_odds","title":"Bind the weighted log odds to a tidy dataset — bind_log_odds","text":"Calculate bind posterior log odds ratios, assuming multinomial model Dirichlet prior. Dirichlet prior parameters set using empirical Bayes approach default, uninformative prior also available. Assumes data tidy format, adds weighted log odds ratio column. Supports non-standard evaluation tidyeval framework.","code":""},{"path":"/reference/bind_log_odds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bind the weighted log odds to a tidy dataset — bind_log_odds","text":"","code":"bind_log_odds(tbl, set, feature, n, uninformative = FALSE, unweighted = FALSE)"},{"path":"/reference/bind_log_odds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bind the weighted log odds to a tidy dataset — bind_log_odds","text":"tbl tidy dataset one row per feature set. set Column sets compare features, documents text data. feature Column features identifying differences, words bigrams text data. n Column containing feature-set counts. uninformative Whether use uninformative Dirichlet prior. Defaults FALSE. unweighted Whether return unweighted log odds, addition weighted log odds. Defaults FALSE.","code":""},{"path":"/reference/bind_log_odds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bind the weighted log odds to a tidy dataset — bind_log_odds","text":"original tidy dataset two additional columns. weighted_log_odds: weighted posterior log odds ratio, odds ratio feature distribution within set versus sets. weighting comes variance-stabilization posterior. log_odds (optional, returned requested): posterior log odds without variance stabilization.","code":""},{"path":"/reference/bind_log_odds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bind the weighted log odds to a tidy dataset — bind_log_odds","text":"arguments set, feature, n passed expression support rlang::quasiquotation; can unquote strings symbols. Grouping preserved ignored. default empirical Bayes prior inflates feature counts group total feature counts across groups. like using moment based estimator parameters Dirichlet prior. Note empirical Bayes estimates perform well average, can surprising properties. uncomfortable empirical Bayes estimates, suggest using uninformative prior. weighted log odds computed function also z-scores log odds; quantity useful comparing frequencies across sets relationship odds ratio straightforward weighting. dataset must exactly one row per set-feature combination calculation succeed. Read Monroe et al (2008) weighted log odds ratio.","code":""},{"path":"/reference/bind_log_odds.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bind the weighted log odds to a tidy dataset — bind_log_odds","text":"Monroe, B. L., Colaresi, M. P. & Quinn, K. M. Fightin' Words: Lexical Feature Selection Evaluation Identifying Content Political Conflict. Polit. anal. 16, 372-403 (2008). https://doi.org/10.1093/pan/mpn018 Minka, T. P. Estimating Dirichlet distribution. (2012). https://tminka.github.io/papers/dirichlet/minka-dirichlet.pdf","code":""},{"path":"/reference/bind_log_odds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bind the weighted log odds to a tidy dataset — bind_log_odds","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union  gear_counts <- mtcars %>%   count(vs, gear)  gear_counts #>   vs gear  n #> 1  0    3 12 #> 2  0    4  2 #> 3  0    5  4 #> 4  1    3  3 #> 5  1    4 10 #> 6  1    5  1  # find the number of gears most characteristic of each engine shape `vs`  regularized <- gear_counts %>%   bind_log_odds(vs, gear, n)  regularized #>   vs gear  n log_odds_weighted #> 1  0    3 12         1.1728347 #> 2  0    4  2        -1.3767516 #> 3  0    5  4         0.4033125 #> 4  1    3  3        -1.1354777 #> 5  1    4 10         1.5661168 #> 6  1    5  1        -0.4362340  unregularized <- gear_counts %>%   bind_log_odds(vs, gear, n, uninformative = TRUE, unweighted = TRUE)  # these log odds will be farther from zero # than the regularized estimates unregularized #>   vs gear  n   log_odds log_odds_weighted #> 1  0    3 12  0.6968169         1.8912729 #> 2  0    4  2 -1.2527630        -1.9691060 #> 3  0    5  4  0.3249262         0.5549172 #> 4  1    3  3 -0.9673459        -1.7407107 #> 5  1    4 10  1.1451323         2.8421436 #> 6  1    5  1 -0.5268260        -0.6570674"},{"path":"/news/index.html","id":"tidylo-development-version","dir":"Changelog","previous_headings":"","what":"tidylo (development version)","title":"tidylo (development version)","text":"Updated documentation & vignette (well CI)","code":""},{"path":"/news/index.html","id":"tidylo-010","dir":"Changelog","previous_headings":"","what":"tidylo 0.1.0","title":"tidylo 0.1.0","text":"CRAN release: 2020-05-25 Initial release weighted log odds using tidy data principles","code":""}]
